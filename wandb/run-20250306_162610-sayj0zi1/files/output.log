Number of response logs 24000
[Epoch 1]
Training: 100%|█████████████████████████████████████████████████████| 75/75 [00:01<00:00, 40.76it/s]
Average loss: 1.5573638343811036
Evaluating: 100%|██████████████████████████████████████████████████| 19/19 [00:00<00:00, 101.02it/s]
Traceback (most recent call last):
  File "d:\Git\Over-estimate\run.py", line 76, in <module>
    sys.exit(main(config_dict))
             ^^^^^^^^^^^^^^^^^
  File "d:\Git\Over-estimate\run.py", line 72, in main
    ncdm.train(datahub, "train", "test", valid_metrics=validate_metrics, batch_size=config['batch_size'],epoch=config['epoch'], weight_decay=0, lr=4e-3)
  File "d:\Git\Over-estimate\inscd\models\static\neural\ncdm.py", line 59, in train
    self._train(datahub=datahub, set_type=set_type,
  File "d:\Git\Over-estimate\inscd\_base.py", line 52, in _train
    self.score(datahub, valid_set_type, valid_metrics, **kwargs)
  File "d:\Git\Over-estimate\inscd\models\static\neural\ncdm.py", line 69, in score
    return self._score(datahub=datahub, set_type=set_type, metrics=metrics, batch_size=batch_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "d:\Git\Over-estimate\inscd\_listener.py", line 33, in wrapper
    result = self.__format(func(*args, **kwargs))
                           ^^^^^^^^^^^^^^^^^^^^^
  File "d:\Git\Over-estimate\inscd\_base.py", line 68, in _score
    return ruler(self, datahub, set_type, pred_r, metrics)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "d:\Git\Over-estimate\inscd\_ruler.py", line 156, in __call__
    results[metric] = self.__method_map[metric](true_r, pred_r)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "d:\Git\Over-estimate\inscd\_ruler.py", line 31, in accuracy
    return accuracy_score(true_r, np.array(pred_r) >= self.threshold)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admin.DESKTOP-7USASVH\AppData\Local\Programs\Python\Python312\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admin.DESKTOP-7USASVH\AppData\Local\Programs\Python\Python312\Lib\site-packages\sklearn\metrics\_classification.py", line 231, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admin.DESKTOP-7USASVH\AppData\Local\Programs\Python\Python312\Lib\site-packages\sklearn\metrics\_classification.py", line 112, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of multiclass and multilabel-indicator targets
