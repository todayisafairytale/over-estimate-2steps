Number of response logs 24000
[Epoch 1]
Training:   0%|                                                              | 0/75 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "d:\Git\Over-estimate\run.py", line 76, in <module>
    sys.exit(main(config_dict))
             ^^^^^^^^^^^^^^^^^
  File "d:\Git\Over-estimate\run.py", line 72, in main
    ncdm.train(datahub, "train", "test", valid_metrics=validate_metrics, batch_size=config['batch_size'],epoch=config['epoch'], weight_decay=0, lr=4e-3)
  File "d:\Git\Over-estimate\inscd\models\static\neural\ncdm.py", line 59, in train
    self._train(datahub=datahub, set_type=set_type,
  File "d:\Git\Over-estimate\inscd\_base.py", line 50, in _train
    unifier.train(datahub, set_type, self.extractor, self.inter_func, **kwargs)
  File "d:\Git\Over-estimate\inscd\_unifier.py", line 49, in train
    loss.backward()
  File "C:\Users\admin.DESKTOP-7USASVH\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "C:\Users\admin.DESKTOP-7USASVH\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\autograd\__init__.py", line 267, in backward
    _engine_run_backward(
  File "C:\Users\admin.DESKTOP-7USASVH\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\autograd\graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
